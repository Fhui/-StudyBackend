spring:
  application:
    name: study
  main:
    allow-bean-definition-overriding: true
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://120.55.58.133:3306/harry?useSSL=true&useUnicode=true&characterEncoding=utf-8
    username: root
    password: clannad
    type: com.alibaba.druid.pool.DruidDataSource
    #最大活跃数
    maxActive: 20
    #初始化数量
    initialSize: 1
    #最大连接等待超时时间
    maxWait: 60000
    #打开PSCache，并且指定每个连接PSCache的大小
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    #通过connectionProperties属性来打开mergeSql功能；慢SQL记录
    #connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    minIdle: 1
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: select 1 from dual
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    #配置监控统计拦截的filters，去掉后监控界面sql将无法统计,'wall'用于防火墙
    filters: stat,wall,logback
  redis:
    database: 0
    host: 120.55.58.133
    port: 6379
    password:
    jedis:
      pool:
        max-active: 8
        max-wait: -1ms
        max-idle: 8
        min-idle: 0
    timeout: 200ms


  aop:
    proxy-target-class: true
  kafka:
#    bootstrap-servers: 192.168.1.164:9092
    bootstrap-servers: 120.55.58.133:9092
    producer:
      topic: harryProduce
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      topic: harryProduce
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      group-id: kafka


server:
  port: 8061

mybatis:
  type-aliases-package: com.harry.entity
  mapper-locations: classpath:mybatis/mapper/**/*.xml

